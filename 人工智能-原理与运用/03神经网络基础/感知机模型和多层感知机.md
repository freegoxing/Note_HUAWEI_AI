# 单层感知机
感知机算法是基于 M-P 模型上发展的新算法，目的是通过学习算法自动调整权重，是模型可以正确分类数据。感知机算法引入了学习机制，是模型可以处理更多的输入情况。
而单层感知机就是感知机算法的具体体现，是一个简单的神经网络结构，由一层输入节点和一层输出节点组成，每一个输入节点链接到输出节点，并通过可调的权重进行计算。它和 M-P模型类似，是一个线性分类器，常用于而分类任务。
但与其不同的是，单层感知机模型可以通过学习算法自动调整权重和偏置（偏置类似与 M-P 模型的阈值），并且它的输入是连续的
![400](assets/感知机模型和多层感知机/file-20251116171409670.png)
## 感知机模型的结构
#### 输出层
和 M-P 模型一样，接受输入数据，不同之处在与感知机模型可以为连续值，而 M-P 模型只能是二进制
#### 输出层
和 M-P 模型一样，由一个神经元构成，不同之处在于此神经元除了对输入信号进行加权和，还需要加上一个偏置值（$b_{i}$）
#### 激活函数
通常使用[[../../HCIA-AI/2-深度学习和大模型基础/全连接神经网络以及训练流程#阶跃函数|阶跃函数]]或符号函数，将加权和转换为输出
## 感知机模型数学表达
- 输出特征加权和：对所有输入特征进行加权和，再加上偏置
$$
z=\sum w_{i}x_{i}+b
$$
- 激活函数：将上面的加权和加上偏置后，输入到激活函数，得到输出结果
$$
y=\begin{cases}
\begin{align}
&0&z<\theta  \\
&1&z\geq \theta
\end{align}
\end{cases}
$$
## 感知机的训练过程
感知机与 M-P 模型最大的不同就是感知机的权重和偏置并非人工设定，而是通过学习自我调整的
常用的算法是感知机学习算法，步骤如下
- 初始化权重和偏置：初始化为0或小的随机值
- 对每一个训练样本，进行下面的操作
	- 计算感知机输出
	- 根据实际输出与预测输出之间的差异，更新权重和偏置
$$
\begin{gather}
\omega_{i}  \leftarrow w_{i}+\eta(y_{true}-y_{pred})x_{i} \\
b \leftarrow b+\eta (y_{true}-y_{pred})
\end{gather}
$$
其中$\eta$是学习率，控制更新的
