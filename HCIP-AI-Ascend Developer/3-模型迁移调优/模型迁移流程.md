# 模型迁移调优整体框架 
- [[模型迁移流程#迁移分析|迁移分析]]
- [[模型迁移流程#模型迁移|模型迁移]]
- [[模型调优流程#精度调试|精度调试]]
- [[模型调优流程#性能调优|性能调优]]
# 迁移分析 
#### 模型选取与约束说明 
- 调研业务需求场景，选取主流仓库模型。 
- 保证选取的模型在第三方硬件平台（如GPU）可成功运行。 
- 明确迁移前模型运行的硬件型号、精度、性能基线。可从权威网站或数据平台获取源模型的性能值基线，或在三方平台实测性能基线。
#### 迁移支持度分析 
- 准备NPU环境，获取模型的源码、权重和数据集等文件。 
- 使用迁移分析工具采集目标网络中的模型/算子清单，识别第三方库及目标网络中算子支持情况，分析模型迁移的可行性。 
- 算子开发与适配：在迁移支持度分析中如果存在平台未支持的算子，可通过修改模型脚本，使用等价支持的算子替换的方式解决，或者开发算子完成适配。
#### 模型选取 
- 在选取迁移模型时，尽可能选取权威PyTorch模型实现仓，对于大语言模型，使用较为广泛的资源仓库。 
#### 约束说明 
- 迁移前要保证选定的模型能在GPU或CPU上运行，并输出精度和性能基线。 
- 模型迁移前需要完成昇腾PyTorch训练环境安装，以完成迁移支持度分析与后续的模型训练， 可参考相关教程完成环境安装，包括NPU驱动固件、CANN软件toolkit、二进制算子包以及 PyTorch框架的安装。 
- 了解目前不支持的优化器或框架。
## 迁移分析工具
在执行迁移操作前，需借助PyTorch Analyse工具，分析基于GPU平台的PyTorch训练脚本中API、三方库套件、亲和API分析以及动态shape在昇腾AI处理器上的支持情况，分析内容主要包括： 
- API支持情况分析 
	- 用户提供待分析的PyTorch训练脚本，可快速获得训练脚本中不支持的torch API和cuda API信息，并输出训练脚本中API精度和性能调优的专家建议。 
- 三方库套件分析 
	- 用户提供待分析的三方库套件源码。可快速获得源码中不支持的三方库API和cuda信息。（三方库API是指在三方库代码中的函数，如果某函数的函数体内使用了不支持的torch算子或者cuda自定义算子，则此函数就是三方库不支持的API。如果第三方库中其他函数调用了这些不支持的API，则这些调用函数也为不支持的API。）
- 动态shape分析 
	- 用户提供待分析的PyTorch训练脚本，可快速获得该训练脚本中包含的动态shape信息。 
- 亲和API分析 
	- 用户提供待分析的PyTorch训练脚本，可快速获得该训练脚本中可替换的亲和API信息。在迁移可行性分析中如果存在平台未支持的算子，可通过修改模型脚本，使用等价支持的算子替换的方式解决，或者开发算子完成适配。
# 模型迁移
#### 模型脚本迁移 
- 通过模型脚本迁移，实现GPU->NPU的接口替换、NPU分布式框架改造。 
#### 环境变量和脚本配置 
- 参考文档中环境变量配置，配置训练相关环境变量，以保证模型训练可以在昇腾NPU上正常运行。 
- 参考文档中模型脚本与启动脚本配置，根据实际场景选择相应操作完成模型脚本和启动脚本配置。 
#### 关键特性适配 
- 数据类型为BF16或FP32的模型训练过程中出现的收敛异常，可开启特征值检测，用于检测在训练过程中的梯度特征值是否存在异常。 
- 在训练时如需混合使用单精度（FP32）与半精度（FP16）数据类型，可参考混合精度适配。
#### 模型调试 
- 迁移适配过程中，如果遇到问题，可以通过模型调试定位问题发生的代码位置。 
- 常见问题发生场景包括环境配置，脚本配置，硬件配置与集群配置问题，可从以上场景角度排查问题。 
#### 模型保存与导出 
- 参考模型保存与导出，保存模型文件用于在线推理，使用模型文件导出ONNX模型通过ATC工具将其转换为适配昇腾AI处理器的.om文件用于离线推理。
## 模型脚本迁移方式 
#### 自动迁移
在训练脚本中导入脚本转换库，然后拉起脚本执行训练。训练脚本在运行时， 会自动将脚本中的CUDA接口替换为昇腾AI处理器支持的NPU接口。整体过程为边训练边转换。 
#### 工具迁移
使用迁移工具PyTorch GPU2Ascend，自动将训练脚本中的CUDA接口替换为昇腾AI处理器支持的NPU接口，并生成迁移报告（脚本转换日志、不支持算子的列表、脚本修改记录）。训练时，运行转换后的脚本。整体过程为先转换脚本，再进行训练。 
#### 手工迁移
通过分析模型，对比GPU与NPU接口，手动对训练脚本进行修改，以支持在昇腾AI处理器上执行训练。迁移要点如下： 
- 定义NPU为训练设备，将训练脚本中适配GPU的接口切换至适配NPU的接口。 
- 多卡迁移需将通信方式修改为昇腾支持的HCCL。
## 自动迁移
自动迁移操作简单，且修改内容少，只需在训练脚本中导入transfer_to_npu即可完成脚本迁移。 
- 当前自动迁移暂不支持channel_last特性，建议用户使用contiguous代替。 
- 若原脚本中使用的backend为nccl，在`init_process_group`初始化进程组后，backend已被自动迁移工具替换为hccl。如果后续代码逻辑包含backend是否为nccl的判断，例如 `assert backend in ['gloo', 'nccl']`、`if backend == 'nccl'`，请手动将字符串nccl改写为hccl。 
- 由于自动迁移工具使用了Python的动态特性，但torch.jit.script不支持Python的动态语法， 因此用户原训练脚本中包含torch.jit.script时使用自动迁移功能会产生冲突，目前自动迁移时会屏蔽torch.jit.script功能，若用户脚本中必须使用torch.jit.script功能，请使用工具进行迁移。
#### 注意事项 
- 如果模型包含评估、在线推理功能，也可在对应脚本中导入自动迁移库代码，并通过对比评估推理结果和日志打印情况，判断与GPU/CPU是否一致决定是否迁移成功； 
- 若训练过程中提示部分CUDA接口报错，可能是部分API（算子API或框架API）不支持引起，用户可参考以下方案进行解决； 
- 使用迁移分析工具对模型脚本进行分析，获得支持情况存疑的API列表，进入昇腾开源社区提出ISSUE求助；算子可通过修改模型脚本，使用等价支持的算子替换的方式解决，或者开发算子完成适配。
## 工具迁移
工具迁移支持使用命令行方式迁移。 
- 若用户训练脚本中包含NPU平台不支持的amp_C模块，需要用户手动删除后再进行训练； 
- 由于转换后的脚本与原始脚本平台不一致，迁移后的脚本在调试运行过程中可能会由于算子差异等原因而抛出异常，导致进程终止，该类异常需要用户根据异常信息进一步调试解决。
![[HCIP-AI-Ascend Developer V2.0 培训教材 .pdf#page=368&rect=75,461,466,633&color=note|HCIP-AI-Ascend Developer V2.0 培训教材 , p.368]]
## 手工迁移
手工迁移需要用户对AI模型有迁移基础，了解GPU与NPU的接口设计的异同点以及各种迁移手段。手工迁移过程中，各个模型使用的迁移方法不完全相同，下文给出手工迁移的核心要点。
#### 单卡迁移 
1. 导入NPU相关库。 
2. 指定NPU作为训练设备。指定训练设备需修改模型训练脚本，有两种指定方式： 
	- to(device)方式：定义好device后可通过`xx.to(device)`的方式将模型或数据集等加载到GPU或NPU上，如 `model.to(device)`。该方式可以指定需要的训练资源，使用比较灵活； 
	- set_device方式：调用set_device接口，指定训练设备。需注意该方式不会自动使用NPU，用户需要手动在想使用NPU的地方，添加`xx.npu()`代码，将模型数据集等加载到NPU上，如`model.npu()`。
3. 替换CUDA接口：将训练脚本中的CUDA接口替换为NPU接口，例如模型、损失函数、数据集等迁移到NPU上。
	- CUDA接口替换为NPU接口 
		- 迁移前：`torch.cuda.is_available()` 
		- 迁移后：`torch_npu.npu.is_available()` 
	- 模型迁移 
		- 迁移前：`model.cuda(local_rank)` 
		- 迁移后：`model.npu(local_rank)` 
	- 数据集迁移 
		- 迁移前： 
			- `images = images.cuda(local_rank, non_blocking=True)` 
			- `target = target.cuda(local_rank, non_blocking=True)` 
		- 迁移后： 
			- `images = images.npu(local_rank, non_blocking=True)` 
			- `target = target.npu(local_rank, non_blocking=True)` 
#### 多卡迁移（分布式训练迁移） 
- 针对多卡迁移（分布式训练迁移），除单卡迁移包含的3个修改要点外，在分布式场景下， 还需要切换通信方式，直接修改`init_process_group`的值。 
- 修改前，GPU使用nccl方式： 
	- `dist.init_process_group(backend='nccl',init_method="tcp://127.0.0.1:**", ...... ,rank=args.rank)` # ** 为端口号，根据实际选择一个闲置端口填写 
- 修改后，NPU使用hccl方式： 
	- `dist.init_process_group(backend='hccl',init_method="tcp://127.0.0.1:**", ...... ,rank=args.rank)` # ** 为端口号，根据实际选择一个闲置端口填写
## 环境变量配置 
在开始训练前，需要先配置训练相关环境变量，用于配置NPU上的PyTorch训练环境，一般使用shell脚本配置，具体包含以下几部分内容： 
- CANN相关环境变量 
- 系统依赖库相关环境变量 
- 自定义环境变量 
- 日志信息配置
## 关键特性适配
#### 特征值检测 
- 特征值检测是针对NPU的PyTorch API，作用是检测在训练过程中激活值的梯度特征值是否存在异常。当前仅能识别数据类型为BF16或FP32的模型在训练过程中出现的收敛异常。 
- 检测原理：开启检测开关后，针对模型训练的反向阶段，采集通信算子和模型最外层的输入tensor，根据预先设置的阈值以及历史值，判断当前激活值梯度是否包含异常大值。若出现异常，当“NPU_ASD_ENABLE”设置为“1”时，只打印异常日志，不上报故障事件；当“NPU_ASD_ENABLE”设置为“2”或“3”时，则终止训练，并将检测到异常的设备上的NPU状态置为Warning，上报故障事件。 
- 特征值异常原因可分为硬件错误和软件错误两类： 
	- 硬件错误：硬件故障导致激活值梯度出现异常大值。 
	- 软件错误：模型异常操作或算子越界，导致出现Inf或NaN等异常特征值
###### 开启检测开关
- 训练前，配置如下环境变量，使能特征值检测并上报告警： 
- `export NPU_ASD_CONFIG=enable:true,with_checksum:true` # 开启特征值检测和Checksum联动功能 
- 注意 
	- 开启特征值检测会导致性能损失，建议在满足如下所有条件时开启，否则性能损失可能大于2%。 
		- 模型规模：70B及以上； 
		- 集群规模：64卡及以上； 
		- torch.npu.set_compile_mode设置：jit_compile=False。 
	- 满足以上条件下，在模型上下文并行（Context Parallel）较大时，Ring Attention特性会在模型反向传播过程中引入大量P2P通信，性能损失可能大于2%。
#### 混合精度适配：AMP
混合精度训练是在训练时混合使用单精度（FP32）与半精度（FP16）数据类型，使用相同的超参数训练，能达到与FP32几乎相同的精度。
混合精度适配支持两种方式：
- 框架内置的AMP功能模块 
- 第三方APEX混合精度模块
## 模型调试

