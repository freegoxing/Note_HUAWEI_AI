# 精度调试 
## 精度分析与调优的作用 
- 训练过程中的模型精度问题分析，及时处理训练不稳定问题; 
- 分析评价集loss/ppl和模型下游评测任务得分，评估迁移前后的精度差异; 
- 确保迁移前后模型精度差异在可接受范围之内，数据无异常溢出；如果出现精度相关问题，需要借助精度问题分析工具分析
## 计算精度说明
NPU与主流AI处理器之间的计算差异
#### 浮点舍入模式的差异
浮点舍入模式方面，主流AI处理器支持四种舍入模式，而NPU在主流AI处理器的四种模式基础上，增加了A模式和O模式。尽管所有舍入模式都会带来数值精度误差，但NPU通过增加舍入模式的选择，为用户提供了更多灵活性以适应不同的计算需求。相比主流AI处理器，NPU的舍入模式更丰富
- A模式：最近舍入并在尾数为五时选择远离零舍入（正数选择更大数的方向，负数选择更小数的方向）。 
- O模式：最近舍入并在尾数为五时向奇数舍入。 
- 向最接近的可表示的值。 
- 当有两个最接近的可表示的值时首选“偶数”值。 
- 向负无穷大（向下）。 
- 向正无穷大（向上）以及向零（截断）。
默认模式是最近舍入（Round to Nearest），它与四舍五入只有一点不同，对.5的舍入上，采用取偶数的方式
```python
#最近舍入模式：
Round(0.5) = 0
Round(1.5) = 2
Round(2.5) = 2
#四舍五入模式：
Round(0.5) = 1
Round(1.5) = 2
Round(2.5) = 3
```
##  精度调试过程案例
- 案例一：主流AI处理器/NPU的loss对齐 
	- 用户使用高学习率1e-3训练LLaMA2-13B模型，在主流AI处理器和NPU上都发生训练不稳定问题，两者在loss尖刺处始终不能对齐。后来改为低学习率1e-4后，训练稳定性得到极大提升，并且两者的loss也能很好对齐。 
- 案例二：DeepSpeed bug引起的偶发loss尖刺 
	- DeepSpeed分布式优化器中存在计算通信同步bug，会导致脏数据进入，从而引起训练不稳定。这在主流AI处理器和 NPU表现是等同的。 
- 案例三：LLaMA2-1B，7B和13B的训练稳定性问题和下游评测不达标问题 
	- 一开始使用了错误的adam_beta2导致训练不稳定，修复后在13B语言模型上又遇到训练稳定性问题，调低学习率到 1e-4并且关闭dropout后成功训练13B大语言模型，并且在各种下游评测任务上超出预期，实现了业务目标。
## 精度问题来源
主要来源于大模型训练：数据集、超参数、模型结构和算法、浮点计算精度等。 
- 数据集：数据异常触发的训练不稳定、语料混合比例与类型的重要性、数据规模与模型参数规模的匹配。 
- 超参数配置（主要包括优化器选择、学习率设定、梯度裁剪阈值、Loss scale等）：优化器与学习率、梯度裁剪阈值、Loss scale动态调整、Batch尺寸的影响。 
- 模型结构与算法：不同算法影响模型训练效果和收敛的Loss水平，但不影响收敛性。大模型复杂性增加算法实现错误，影响收敛性。新模型结构需调试确保无误，以实现Loss收敛和性能匹配。 
- 计算精度：包括浮点数计算、大模型训练常用数据格式（单精度、半精度浮点数）、张量分布式并行计算（词嵌入输入层embedding张量并行、线性层张量并行、MLP层切分、流水线并行）、混合精度计算分析等。
## 调优方法
- 数据集清洗：非目标语言与低质量样本剔除、去重 
- 超参配置调优：Batch Size配置、学习率、优化器、权重初始化、其他稳定训练技术，例如梯度裁剪（Gradient Clipping）、Weight Decay（[[../../人工智能-原理与运用/03神经网络基础/参数优化方法#L2正则化|L2正则化]]）、特殊层的调整； 
- 使用TensorProbe工具调试模型收敛问题：确定Llama2 loss尖刺根因、确定Open Sora 在deepspeed ZeRO-1设置下不收敛问题 ； 
- 混合精度配置选择：如果混合精度训练中选择float16，为了避免表示范围小引起的浮点上溢和下溢，混合精度要结合动态Loss缩放机制。另外，特定张量计算操作对计算精度也有不同的要求，如[[../../人工智能-原理与运用/03神经网络基础/激活函数#Softmax 函数|Softmax]]、矩阵乘法（Matmul）等使用FP32，[[卷积神经网络|卷积操作与池化]]、[[基于循环神经网络的模型架构|循环神经网络（RNNs）]]等使用BF16
## 保存&导出模型
- PyTorch在训练过程中，通常使用torch.save()来保存Checkpoint文件，根据模型文件的后续用途会保存为两种格式的模型文件（pth文件和pth.tar文件），以便用于在线推理。pth或pt扩展名的文件，用于在线推理或导出ONNX格式模型，仅保存模型参数，不保存模型结构，以便压缩文件的体积，可以用Netron等可视化工具打开。通过state_dict来保存和加载模型（保存为后缀是.pth/.pt的文件时，需要提供模型定义文件，否则后续模型无法部署）
- 模型训练完成后，用户可以使用pth文件和pth.tar文件导出ONNX模型，然后通过ATC工具将其转换为适配昇腾Al处理的.om文件用于离线推理。
- 下面主要介绍如何将Checkpoint文件通过`torch.onnx.export()`接口导出为ONNX模型。
	- ONNX是业内目前比较主流的模型格式，广泛用于模型交流及部署。PyTorch模型在昇腾Al处理器上的部署策略是基于 PyTorch官方支持的ONNX模块实现的。
	- 使用PyTorch框架导出ONNX模型时，框架中设置算子编译选项的`ACL_OP_SELECT_IMPL_MODE`选项默认值为 “high_precision”，用户可根据需要自行修改。用户在使用导出的ONNX模型进行模型转换时，建议设置与训练时相同的模式，以避免因模式选择不同而出现的精度或者性能差异。
# 性能调优
## 性能概念和指标
在计算性能指标中，优先级排序为：
**吞吐率>单步迭代时间>线性度>内存占用>带宽占比>训练效率>浮点计算次数每秒>算力利用率。**
对于一个batch而言，时间主要由以下部分构成
*单batch总时间=数据加载时间+模型前反向时间 +优化器时间+模型后处理时间+通信时间+调度时间*
![[HCIP-AI-Ascend Developer V2.0 培训教材 .pdf#page=391&rect=152,456,405,572&color=red|HCIP-AI-Ascend Developer V2.0 培训教材 , p.391|600]]
## 性能分析工具
性能分析工具是一套基于CANN的分析工具，其目的在于分析NPU在运行中模型的训练效率，在训练有瓶颈或者有性能优化需求的时候，可以利用性能分析工具进行性能分析。工具主要包括： 
- Ascend PyTorch Profiler：基于CANN实现，用于分析CANN上硬件的运行效率和性能数据。
- [[昇腾AI基础软件#MindStudio Insight|MindStudio Insight]]：是一款调优可视化工具，集成了CANN数据的分析和可视化等功能。 
- 性能比对工具、集群分析工具：取自开源社区，对Ascend PyTorch Profiler采集得到的数据进行专项分析
## 性能优化流程
![[HCIP-AI-Ascend Developer V2.0 培训教材 .pdf#page=393&rect=93,454,436,643&color=red|HCIP-AI-Ascend Developer V2.0 培训教材 , p.393]]
## 通用优化方法
#### 并行策略
- 在面临显存不足、模型过大无法完全加载以及需要进行切分的情况下，优先考虑使用[[昇腾大模型训练解决方案#层内并行（张量并行）|TP]]（Tensor Parallelism）进行切分，并确保切分的数量小于等于机器内的计算卡数。 
- 如果在 TP切分达到最大显存容量仍然不足的情况下，可以考虑在机器之间使用[[昇腾大模型训练解决方案#层间并行（流水线并行）|PP]] （Pipeline Parallelism）进行切分。理论上，PP的数量应该越小越好，以尽可能减少空闲计算资源的浪费。 
- 在机器资源富裕的情况下，可以开启[[昇腾大模型训练解决方案#数据并行(DP)|DP]]（Data Parallelism）并行，将计算任务分配给多个机器进行并行处理，从而提高处理效率。然而，在机器资源有限的情况下，如果开启TP+PP切分后显存仍然不足，可以考虑使用ZeRO1和重计算技术。 
- 此外，即使在模型能够成功运行的情况下，也可以尝试主动地使用降低内存占用的手段， 例如ZeRO1（[[昇腾大模型训练解决方案#ZeRO|ZeRO]]）和重计算等，然后增大Batch Size。这样有时也会取得令人意外的效果。
#### IO优化和调度优化
1. 数据加载优化在PyTorch模型中，数据加载部分的逻辑一般是DataLoader及其衍生类，在DataLoader加载数据中，要注意以下两个核心点： 
	- 第一个是数据加载的预处理部分，数据的预处理通常会写在datasets里，数据的预处理包括对文本、图片、视频和语音等不同格式数据的处理，数据预处理耗时长是比较容易识别出来的，一般通过打点计时。 
	- 第二个就是要确定好数据读取的方式，一般而言，每张卡都去读取数据是比较理想的， 如果存在0卡读取，广播给其他卡的数据读取形式，要关注其性能如何，很多时候都会让模型性能严重劣化。
2. 调度优化
	- 自动绑核 
		- 绑核功能通过绑定指定CPU核心和设备指定卡，来减少核心切换开销，优化调度性能。
		- *当前仅有方案：将CPU核数按环境卡数平均分配并绑核，如192核8卡场景，0卡会绑定至0-23，1卡绑定至24-47，以此类推*
#### NPU亲和适配优化
###### 融合算子 
融合算子的优化原理为：通过数学意义上的等价替换，将多个算子融为一个算子的计算，减少冗余计算，同时减少下发次数，从而提高性能
###### 消除多余的stream同步
###### 部分CPU上运行的优化方法
#### 内存优化
###### 调整内存参数
###### 多流复用
###### 减小HCCL通信缓存
###### Python GC优化
#### 通信优化
###### HCCL_INTRA_ROCE_ENABLE
###### HCCL_RDMA_TC
###### HCCL_RDMA_SL
###### HCCL_BUFFSIZE
