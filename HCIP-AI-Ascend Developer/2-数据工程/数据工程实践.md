# 通用数据处理
## 图片数据预处理
图片的预处理是为了确保模型训练的时候可以提取到通用特征，因此需要做数据增强等操作，同时将尺寸统一，用于固定shape的模型。
![[HCIP-AI-Ascend Developer V2.0 培训教材 .pdf#page=321&rect=162,470,392,591&color=red|HCIP-AI-Ascend Developer V2.0 培训教材 , p.321|500]]
## 视频数据预处理 
视频数据预处理的目标是将原始视频数据转换为适合模型输入的格式，同时保留或增强视频中的关键信息。 
视频数据因其时序性、高维度和动态特性，其预处理流程显著复杂于静态图像
![[HCIP-AI-Ascend Developer V2.0 培训教材 .pdf#page=322&rect=176,485,384,573&color=red|HCIP-AI-Ascend Developer V2.0 培训教材 , p.322|600]]
## 文本数据预处理 
语言是人类特有的概念。人可以理解每个语言单词的意义，但模型无法直接的从感知中抽象出语言符号的意义。 
在模型推理阶段，自然语言文本需转换为模型可以理解的数值表征，比如整数、浮点数或者向量。
#### 从输入文本到向量
以机器翻译（中译英）为例，下一段输入文本在转化为embedding之前都经历了什么， 具体流程如下
![[HCIP-AI-Ascend Developer V2.0 培训教材 .pdf#page=324&rect=70,449,485,644&color=red|HCIP-AI-Ascend Developer V2.0 培训教材 , p.324]]
- 建立中文词表和英文词表：此步骤会把语料库中的文字去重、然后排序之后就可以得到词汇表。每个字符在词表中有唯一序号。 
- 整理文本：把段落等裁剪成短文本。 
- 分词：将连续的文本拆分/转换成一个个独立的最小语义单元。生成的每个单元称为token。具体又包括如下几步： 
	- 标准化：对文本进行必要的清理工作，例如清理特殊符号、格式转换、过滤停用词、Unicode标准化等。 
	- 预分词：将输入拆分为单词。 
	- 分词模型处理：把预分词器得到的单词送进分词模型进行分词，得到 token序列。比如图中today变成##day是使用的子词分词法，##是一个特殊标记，表明该子词是前一个词的延续，而不是一个独立的词。 
	- 后处理：添加分词器的特殊token，生成注意力掩码等。此时token仅仅是字符串，还不能直接用于模型的计算。 
- 索引化：通过词表将token转换成计算机更容易处理的数字信息。每个token都会去词表中查询，得到该token在词表中的序号，这个序号就是每个token对应的one-hot向量。
#### 文本分词：分词器的组成部分
需要依赖专门的工具分词器（Tokenizer）可以高效且准确地完成分词过程
分词器一般包含以下几个部分： 
- Trainer（分词训练器/算法）：给定训练数据，用Trainer封装的分词算法，生成词表。 
- Vocabulary（词表）：词表是分词的标准。基本上每个语言任务都需要维护一个词表，词表可以是根据当前训练数据生成的，也可以直接加载前人预训练好的词表。 
- Encoder（编码器）：拥有词表后，给定语料，编码器把语料按词表拆分token，并记录token 在词表中的索引，拥有该索引则可将token表示成one-hot向量入模，再做后续的embedding 等优化操作。 
- Decoder（解码器）：给定一串索引，将索引还原成最初的语料形式。
# LLM数据处理
## LLM训练对数据的要求 
大规模无标注数据预训练 + 指令微调 + 对齐
![[HCIP-AI-Ascend Developer V2.0 培训教材 .pdf#page=328&rect=86,455,463,609&color=red|HCIP-AI-Ascend Developer V2.0 培训教材 , p.328]]
*预训练的时间是最长的*
