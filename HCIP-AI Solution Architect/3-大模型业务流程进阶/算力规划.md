## 大模型训练需要足够数据与算力，以及大规模分布式训练
Scaling law三要素：随着模型的参数规模和训练数据越多，训练效果会越好。
-  模型规模（参数数量，Parameters）
- 训练数据量 （Dataset Size）
- 计算资源（Compute）
单卡算力和存储不足以支撑大模型的训练，因此需要支持多种分布式并行训练策略
- 数据并行：切分训练数据的batch （[[昇腾大模型训练解决方案#数据并行(DP)]]）
- Tensor并行：切分每一层的 tensor （[[昇腾大模型训练解决方案#模型并行(MP)]]）
- Pipeline并行：切分模型的层（[[昇腾大模型训练解决方案#模型并行(MP)]]）
## 大模型训练对计算资源的需求
对于每一个 $token$，每一个模型参数需要进行 $2\times 4 = 8$次浮点运算
- 前向传递+后向传递+激活重计算的系数$=1+2+1=4$
- 使用激活重计算的一次训练迭代$=2\times 4=8$
$$
\text{训练时间} \approx \frac{8\times tokens\text{数}\times \text{模型参量}}{GPU\text{数}\times GPU \text{峰值}flops \times GPU\text{利用率}}
$$
```ad-example
以GPT3 175B模型，300B tokens位例，在1024张算力为312TFlops(A100)的效率为45%
$$
\text{训练时间} \approx \frac{8\times \left( 300 \times 10^9 \right) \times \left( 175 \times 10 ^ 9 \right) }{1024 \times \left( 312\times 10 ^{12} \right)  \times 0.45} \approx 2921340 \ s \approx 34\ days
$$
```
## 大模型的网络带宽需求
![[HCIP-AI Solution Architect V1.0 培训教材.pdf#page=195&rect=86,526,442,632&color=red|HCIP-AI Solution Architect V1.0 培训教材, p.195]]
从上表也可以看出，数据并行和流水并行对节点间的带宽要求较低；但专家并行（MoE ），需要节点间较高的带宽才可以支持。
## 大模型的存储需求
#### 数据处理对存储需求
- 原始数据集存储 
- 训练数据集存储 ：原始数据集经过数据清洗、过滤、格式化等处理得到训练数据集，一般是 10+ 倍左右的压缩关系；
#### 训练对存储的需求
- 训练数据集拉取：一次性从存储拉取到内存
- Checkpoint 拉取
- Checkpoint周期性保存
```ad-note
title:checkpoint（检查点）
在机器学习和深度学习中，checkpoint 是指在模型训练过程中保存的模型状态。这些检查点通常包括模型的参数（权重和偏置）、优化器状态和其他相关的训练信息。通过保存检查点，您可以在训练过程中定期保存模型的当前状态，以便在需要时恢复训练或用于模型评估和推理。
```
![[HCIP-AI Solution Architect V1.0 培训教材.pdf#page=196&rect=121,451,463,550&color=red|HCIP-AI Solution Architect V1.0 培训教材, p.196]]
## DeepSeek系列模型典型场景需求分析
![[HCIP-AI Solution Architect V1.0 培训教材.pdf#page=197&rect=95,477,459,611&color=red|HCIP-AI Solution Architect V1.0 培训教材, p.197]]