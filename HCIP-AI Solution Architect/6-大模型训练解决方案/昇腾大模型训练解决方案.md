# AI开发框架 
## AI开发框架的作用
-  数据预处理
-   开发接口
-  调试调优 
-  编译&执行
-  推理部署
## [[昇腾AI基础软件#MindSpore|MindSpore]]
![[昇腾AI基础软件#MindSpore]]
## PyTorch
PyTorch 是一个针对深度学习, 并且使用GPU和NPU来优化的tensor library。是当前的主流深度学习框架之一。

# 分布式并行策略 
## 分布式模型训练
大模型在训练时往往需要大量内存来存储中间激活、权重等参数，百亿模型甚至无法在单个GPU上进行训练，使得模型训练在某些情况下非常低效和不可能。这就需要进行多卡，或者多节点分布式训练
分布式并行的**核心思想是把计算和存储分散到不同的设备**。大规模深度学习模型训练主要范式： 
- 数据并行（Data Parallelism，DP） 
- 模型并行（Model Parallelism，MP） 
- 混合并行（Hybrid Parallelism，HP）
## 数据并行(DP)
每个计算设备都有神经网络模型的完整副本，进行迭代时，每个计算设备只分配了一个批次数据样本的子集，并根据该批次样本子集的数据进行网络模型的前向和反向计算
![[HCIP-AI Solution Architect V1.0 培训教材.pdf#page=390&rect=301,457,481,598&color=red|HCIP-AI Solution Architect V1.0 培训教材, p.390|500]]
数据并行将训练数据划分为多个批次，并将每个批次分配给不同的设备进行并行处理， 每张计算卡都并行处理不同批次的数据，然后将结果合并
## 模型并行(MP)
模型并行多用于解决单节点内存不足的问题。模型并行从计算图的切分角度，可以分为以下两种：
![[HCIP-AI Solution Architect V1.0 培训教材.pdf#page=391&rect=153,466,390,551&color=red|HCIP-AI Solution Architect V1.0 培训教材, p.391|600]]
#### 层内并行（张量并行）
将层内的参数切分到不同设备中。 
#### 层间并行（流水线并行）
按层切分，将不同的层放置到不同的设备中。
## 混合并行（HP）
混合并行是将多种并行策略如数据并行、流水线并行和张量并行等进行混合使用。通过结合不同的并行策略，混合并行可以充分发挥各种并行策略的优点，以最大程度地提高计算性能和效率。
## 深度学习模型软件体系架构
大模型训练加速库，位于模型训练框架和模型之间，用来提升训练、推理等。
![[HCIP-AI Solution Architect V1.0 培训教材.pdf#page=393&rect=111,476,445,608&color=red|HCIP-AI Solution Architect V1.0 培训教材, p.393]]
## DeepSpeed简介
DeepSpeed是一个由微软开发的开源深度学习优化库，旨在提高大规模模型训练的效率和可扩展性。它通过多种技术手段来加速训练，包括模型并行化、梯度累积、动态精度缩放、本地模式混合精度等
## DeepSpeed软件架构
DeepSpeed主要包含三部分： 
- APIs：提供易用的api接口，训练模型、推理模型只需要简单调用几个接口即可。其中最重要的是initialize接口，用来初始化引擎，参数中配置训练参数及优化技术等。配置参数一般保存在 config.json文件中。 
- Runtime：运行时组件，是DeepSpeed管理、执行和性能优化的核心组件。如部署训练任务到分布式设备、数据分区、模型分区、系统优化、微调、故障检测、checkpoints保存和加载等。该组件使用python语言实现。 
- Ops：用C++和cuda实现底层内核，优化计算和通信，提供了一系列底层操作等。

架构优势： 
- 可以在训练框架上进行两部分（训练和推理分开）优化。 
- 与紧密耦合的结构比，该结构可以更好的利用整个生态，且与深度集成相比，更容易维护。 
- 与基础设置无关，用户可以选择喜欢的平台，如Azure ML、Azure VMs等。
## ZeRO
ZeRO （Zero Redundancy Optimizer）是微软DeepSpeed框架中提出的一种显存优化技术， 其核心理念是通过分布式存储和按需加载模型状态，消除内存冗余，从而在有限硬件资源下支持超大规模模型训练
其原理分为三个阶段，逐步优化显存占用： 
- ZeRO-1：优化器状态分片 
	- 目标：将优化器参数（如Adam的动量、方差）分散到多个GPU。 
	- 实现：每个GPU仅存储部分优化器状态，但保留完整的模型参数和梯度。 
	- 效果：显存占用减少约8倍（针对Adam优化器），适用于中等规模模型。
- ZeRO-2：梯度分片 
	- 目标：在ZeRO-1基础上进一步分散梯度。 
	- 实现：梯度通过reduce操作同步到对应GPU，而非全局all-reduce。 
	- 效果：显存占用进一步降低，支持更大模型训练。
- ZeRO-3：模型参数分片 
	- 目标：彻底消除冗余，分片所有模型状态（参数、梯度、优化器状态）。 
	- 实现：前向计算时仅加载当前层参数，反向传播后同步更新。 
	- 效果：显存占用最小化，但通信开销增加，需高效通信框架（如NCCL）支持。
## [[昇腾AI基础软件#MindSpeed|MindSpeed]]
![[昇腾AI基础软件#MindSpeed]]

# CANN 
## [[昇腾AI基础软件#CANN|CANN]]
![[昇腾AI基础软件#CANN]]
- AOL算子加速库（Ascend Operator Library），提供了丰富的深度优化、硬件亲和的高性能算子，包括神经网络（Neural Network，NN）库、线性代数计算库（Basic Linear Algebra Subprograms，BLAS）等，为神经网络在昇腾硬件上加速计算奠定了基础。 
- HCCL集合通信库（Huawei Collective Communication Library），是基于昇腾硬件的高性能集合通信库，提供单机多卡以及多机多卡间的数据并行、模型并行集合通信方案。 HCCL支持AllReduce、Broadcast、Allgather、ReduceScatter、AlltoAll等通信原语，Ring、 Mesh、HD等通信算法，在HCCS、RoCE和PCIe高速链路实现集合通信。
#### HCCL
基于昇腾AI处理器的高性能集合通信库，提供单机多卡以及多机多卡间的数据并行、模型并行集合通信方案。 
HCCL提供了C与Python两种语言的接口，其中C语言接口用于实现单算子模式下的框架适配，例如HCCL单算子API嵌入到PyTorch后端代码中
集合通信库软件架构分为三层： 
- 适配层，图引擎与单算子适配，提供通信域管理及通信算子接口。 
- 集合通信业务层，包含通信框架与通信算法两个模块： 
	- 通信框架：负责通信域管理，通信算子的业务串联，协同通信算法模块完成算法选择，协同通信平台模块完成资源申请并实现集合通信任务的下发。 
	- 通信算法：作为集合通信算法的承载模块，提供特定集合通信操作的资源计算，并根据通信域信息完成通信任务编排。 
- 集合通信平台层，提供NPU之上与集合通信关联的资源抽象，并提供集合通信的相关维护、测试能力
#### Ascend C 算子编程语言，使能算子极简开发
Ascend C是CANN针对算子开发场景推出的编程语言，原生支持C和C++标准规范，兼具开发效率和运行性能
#### AOL
CANN（Compute Architecture for Neural Networks）提供了算子加速库 （ Ascend Operator Library ， 简称 AOL）。该库提供了一系列丰富的深度优化、硬件亲和的高性能算子
## 大模型分布式训练需要“可部署、通信快、算得快”三大能力
#### 可部署
大模型在内存受限的卡上部署合理的分布式切分策略 + 内存优化策略
#### 通信快
集群通信域更大，通信性能需要优化高带宽协议、数据通信拖尾、bubble占比降
#### 算得快
充分发挥算力，提升算力利用率高频算子优化、融合、加速库
# 开发工具 
## [[昇腾AI基础软件#MindStudio|MindStudio]]
MindStudio是华为面向昇腾AI开发者提供的工具集，提供一站式AI开发环境，采用插件化扩展机制， 打造高效、便捷的全流程开发工具链。
支持模型开发、应用开发以及算子开发三个主流程中的开发任务
#### 关键特性
- 精度调试
- 性能调优
- 上板调试
#### 功能全览
![[HCIP-AI Solution Architect V1.0 培训教材.pdf#page=418&rect=80,473,479,620&color=red|HCIP-AI Solution Architect V1.0 培训教材, p.418]]
#### 工程管理
MindStudio支持创建以下类型的昇腾工程： 
- 模型训练工程 
- 应用开发工程 
- 算子开发工程 
MindStudio支持创建和导入纯语言类（C/C++、Java、Python）工程、Empty工程。  
MindStudio支持非昇腾工程转换为昇腾工程的功能。
#### 推理一体化工具
提供模型推理一体化入口AMIT（Ascend Model Inference Tool），支持用户在统一入口下调用模型分析、模型转换、离线模型dump、精度比对和性能分析工具，提升开发效率
#### 模型训练
MindStudio支持MindSpore、TensorFlow和PyTorch框架的模型训练，把执行的脚本、数据集、参数等相关信息通过网络分析并输出分析结果
MindInsight为MindSpore提供了简单易用的调优调试能力。在训练过程中，可以将标量、张量、图像、计算图、模型超参、训练耗时等数据记录到文件中，通过 MindInsight可视化页面进行查看及分析。
#### 模型转换和调优 
模型转换和调优是将Caffe/TensorFlow等框架训练好的模型，通过ATC或者AOE工具将其转换为昇腾AI处理器支持的离线模型。 
- ATC工具：ATC会进行算子调度优化、权重数据重排、内存使用优化等具体操作，对原始的深度学习模型进行进一步的调优，从而满足部署场景下的高性能需求，使其能够高效执行在昇腾AI 处理器上。
- AOE工具：AOE通过生成调优策略、编译、在运行环境上验证的闭环反馈机制，不断迭代出更优的调优策略，最终得到最佳的调优策略，从而可以更充分利用硬件资源，不断提升网络的性能，达到最优的效果。
	- 子图调优：通过SGAT（SubGraph Auto Tune），对子图切分策略进行调优，通过在运行环境上验证获得真实性能，最终将最优的调优策略固化至模型知识库， 并获取优化后的模型。 
	- 算子调优：通过OPAT（Operator Auto Tune），对算子进行调优，通过在运行环境上验证获取真实性能，最终将优选算子调优策略固化到算子知识库。
# AI应用使能套件
## 大模型使能套件：全流程覆盖大模型开发、训练、微调、推理
![[HCIP-AI Solution Architect V1.0 培训教材.pdf#page=425&rect=80,468,480,630&color=red|HCIP-AI Solution Architect V1.0 培训教材, p.425]]
## ModelShow 
直观观察昇腾NPU训练的模型效果。
## [[昇腾AI基础软件#Mind X|Mind X]]
![[昇腾AI基础软件#Mind X]]